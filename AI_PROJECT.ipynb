{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBJGzSRYjQRX",
        "outputId": "cf963e82-5997-446b-bbae-69a8b910df12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow tensorflow-hub scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def is_paraphrased(original, candidate, threshold=0.8):\n",
        "    # Load the Universal Sentence Encoder\n",
        "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "    # Embed the original and candidate paragraphs\n",
        "    original_embedding = embed([original])[0].numpy()\n",
        "    candidate_embedding = embed([candidate])[0].numpy()\n",
        "\n",
        "    # Compute the cosine similarity between the embeddings\n",
        "    similarity = cosine_similarity([original_embedding], [candidate_embedding])[0][0]\n",
        "\n",
        "    # Compare the similarity with the threshold\n",
        "    if similarity >= threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    # Get input paragraphs from the user\n",
        "    original_paragraph = input(\"Enter the original paragraph: \")\n",
        "    candidate_paragraph = input(\"Enter the candidate paragraph: \")\n",
        "\n",
        "    # Set a similarity threshold (adjust as needed)\n",
        "    threshold = 0.8\n",
        "\n",
        "    # Check if the candidate paragraph is paraphrased\n",
        "    if is_paraphrased(original_paragraph, candidate_paragraph, threshold):\n",
        "        print(\"The paragraph is paraphrased.\")\n",
        "    else:\n",
        "        print(\"The paragraph is not paraphrased.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zue9oWUcjaG9",
        "outputId": "68599e88-193b-42a6-e8df-51171a63d537"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the original paragraph: Her life spanned years of incredible change for women as they gained more rights than ever before.\n",
            "Enter the candidate paragraph: She lived through the exciting era of women's liberation.\n",
            "The paragraph is not paraphrased.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def levenshtein(seq1, seq2):\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x # row aray with elements of x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y # column array with elements of y\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]: # if the alphabets at the postion is same\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "\n",
        "            else:         # if the alphabbets at the position are different\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "\n",
        "    # returning the levenshtein distance\n",
        "    return (matrix[size_x - 1, size_y - 1])\n",
        "\n",
        "\n",
        "    #one for entire folder with masterfile, one for two separate files , one for all files within the folder\n",
        "\n",
        "choice = int(input(\"Enter 1 for comparing 2 files\\n\"))\n",
        "\n",
        "k=0 # to count the number of plagiarised files\n",
        "\n",
        "if (choice == 1) :\n",
        "   plag = int(input(\"Enter the percentage of plagiarism allowed\\n\"))\n",
        "   path2 = input(\"Enter the path of the first file to scan:\\n\")\n",
        "   path3 = input(\"Enter the path of the second file to scan:\\n\")\n",
        "\n",
        "   with open(path2, 'r') as file:\n",
        "     data = file.read().replace('\\n', '')\n",
        "     str1=data.replace(' ', '')\n",
        "\n",
        "   with open(path3, 'r') as file:\n",
        "     data = file.read().replace('\\n', '')\n",
        "     str2=data.replace(' ', '')\n",
        "\n",
        "   if(len(str1)>len(str2)):\n",
        "        length=len(str1)\n",
        "\n",
        "   else:\n",
        "       length=len(str2)\n",
        "\n",
        "   n = 100-round((levenshtein(str1,str2)/length)*100,2)\n",
        "\n",
        "   if (n>plag):\n",
        "     print(\"\\nFor the files\",path2,\"and\",path3,n,\"% similarity\")\n",
        "     print(\"The given documents are plagarised\")\n",
        "   else :\n",
        "     print(\"\\nSimilarities are below the given level\")\n",
        "     print(\"The documents are not plagarised\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAsvD6qQklYy",
        "outputId": "fabb31fe-f21b-4bb1-b4ef-7288cc0924b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 for comparing 2 files\n",
            "1\n",
            "Enter the percentage of plagiarism allowed\n",
            "20\n",
            "Enter the path of the first file to scan:\n",
            "/content/doc1.txt\n",
            "Enter the path of the second file to scan:\n",
            "/content/doc2.txt\n",
            "\n",
            "For the files /content/doc1.txt and /content/doc2.txt 24.689999999999998 % similarity\n",
            "The given documents are plagarised\n"
          ]
        }
      ]
    }
  ]
}